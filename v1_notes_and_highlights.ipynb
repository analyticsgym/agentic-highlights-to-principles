{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d882e6",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5056b",
   "metadata": {},
   "source": [
    "### Check API Auth to Readwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbc69f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 204\n",
      "✅ Token is valid! You’re authenticated with Readwise.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"READWISE_API_TOKEN\")\n",
    "headers = {\"Authorization\": f\"Token {token}\"}\n",
    "\n",
    "response = requests.get(\"https://readwise.io/api/v2/auth/\", headers=headers)\n",
    "print(\"Status code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 204:\n",
    "    print(\"✅ Token is valid! You’re authenticated with Readwise.\")\n",
    "else:\n",
    "    print(\"❌ Token invalid or expired. Check your .env file or regenerate it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78952c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 55262007,\n",
       " 'title': 'The Miracle of Mindfulness',\n",
       " 'author': 'Thich Nhat Hanh, Vo-Dihn Mai, and Mobi Ho',\n",
       " 'category': 'books',\n",
       " 'source': 'kindle',\n",
       " 'num_highlights': 30,\n",
       " 'last_highlight_at': '2025-10-24T04:56:00.000000Z',\n",
       " 'updated': '2025-10-24T04:02:41.043968Z',\n",
       " 'cover_image_url': 'https://images-na.ssl-images-amazon.com/images/I/41v%2B00gXxyL._SL200_.jpg',\n",
       " 'highlights_url': 'https://readwise.io/bookreview/55262007',\n",
       " 'source_url': None,\n",
       " 'asin': 'B009U9S6VM',\n",
       " 'tags': [],\n",
       " 'document_note': ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the head of the data json\n",
    "data['results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a40b561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                       title  \\\n",
      "0  55262007  The Miracle of Mindfulness   \n",
      "1  55650413                  Click Here   \n",
      "2  55152119                 Mindfulness   \n",
      "3  55400541          Conscious Business   \n",
      "\n",
      "                                      author  num_highlights  \n",
      "0  Thich Nhat Hanh, Vo-Dihn Mai, and Mobi Ho              30  \n",
      "1                               Alex Schultz              62  \n",
      "2                           Joseph Goldstein              28  \n",
      "3                                Fred Kofman               4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_books = pd.DataFrame(data[\"results\"])\n",
    "print(df_books[[\"id\", \"title\", \"author\", \"num_highlights\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178409f",
   "metadata": {},
   "source": [
    "### Check OpenAI API Key and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b10b6316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY found and loaded successfully\n",
      "API key format appears valid\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "### check openai api key\n",
    "##############################################################\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"OPENAI_API_KEY found and loaded successfully\")\n",
    "    # Additional validation: check if it looks like a valid OpenAI key format\n",
    "    if api_key.startswith(\"sk-\") and len(api_key) > 40:\n",
    "        print(\"API key format appears valid\")\n",
    "    else:\n",
    "        print(\"API key format may be incorrect (should start with 'sk-')\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Make sure you have a .env file with OPENAI_API_KEY=your_key_here\")\n",
    "\n",
    "if api_key is None:\n",
    "    print(\"OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Make sure you have a .env file with OPENAI_API_KEY=your_key_here\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66af1f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API connection successful!\n",
      "Response: hi\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "### check openai api connection\n",
    "##############################################################\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=\"Hello! Respond hi if you're working.\"\n",
    "    )\n",
    "    print(\"✅ API connection successful!\")\n",
    "    print(\"Response:\", response.output_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ API connection failed.\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3737696",
   "metadata": {},
   "source": [
    "### OpenAI Input Prompt Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f3ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt-5', 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_in_prompt(prompt: str, model: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(prompt)\n",
    "    return model, len(tokens)\n",
    "\n",
    "example_prompt = \"What is the capital of Texas?\"\n",
    "\n",
    "# Example usage:\n",
    "num_tokens_in_prompt(example_prompt, \"gpt-5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a678cb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Input</th>\n",
       "      <th>Cached input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-5</td>\n",
       "      <td>1.250000e-06</td>\n",
       "      <td>1.250000e-07</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-5-mini</td>\n",
       "      <td>2.500000e-07</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>2.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-5-nano</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>5.000000e-09</td>\n",
       "      <td>4.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-5-chat-latest</td>\n",
       "      <td>1.250000e-06</td>\n",
       "      <td>1.250000e-07</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-5-codex</td>\n",
       "      <td>1.250000e-06</td>\n",
       "      <td>1.250000e-07</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model         Input  Cached input        Output\n",
       "1              gpt-5  1.250000e-06  1.250000e-07  1.000000e-05\n",
       "2         gpt-5-mini  2.500000e-07  2.500000e-08  2.000000e-06\n",
       "3         gpt-5-nano  5.000000e-08  5.000000e-09  4.000000e-07\n",
       "4  gpt-5-chat-latest  1.250000e-06  1.250000e-07  1.000000e-05\n",
       "5        gpt-5-codex  1.250000e-06  1.250000e-07  1.000000e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# manual grab model text cost; couldn't get the web scrape to work, manual for now\n",
    "# https://platform.openai.com/docs/pricing#text-tokens\n",
    "\n",
    "# save the table as a markdown file\n",
    "with open(\"gpt_model_pricing.md\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "|Model|Input|Cached input|Output|\n",
    "|---|---|---|---|\n",
    "|gpt-5|$1.25|$0.125|$10.00|\n",
    "|gpt-5-mini|$0.25|$0.025|$2.00|\n",
    "|gpt-5-nano|$0.05|$0.005|$0.40|\n",
    "|gpt-5-chat-latest|$1.25|$0.125|$10.00|\n",
    "|gpt-5-codex|$1.25|$0.125|$10.00|\n",
    "|gpt-5-pro|$15.00|-|$120.00|\n",
    "|gpt-4.1|$2.00|$0.50|$8.00|\n",
    "|gpt-4.1-mini|$0.40|$0.10|$1.60|\n",
    "|gpt-4.1-nano|$0.10|$0.025|$0.40|\n",
    "|gpt-4o|$2.50|$1.25|$10.00|\n",
    "|gpt-4o-2024-05-13|$5.00|-|$15.00|\n",
    "|gpt-4o-mini|$0.15|$0.075|$0.60|\n",
    "|gpt-realtime|$4.00|$0.40|$16.00|\n",
    "|gpt-realtime-mini|$0.60|$0.06|$2.40|\n",
    "|gpt-4o-realtime-preview|$5.00|$2.50|$20.00|\n",
    "|gpt-4o-mini-realtime-preview|$0.60|$0.30|$2.40|\n",
    "|gpt-audio|$2.50|-|$10.00|\n",
    "|gpt-audio-mini|$0.60|-|$2.40|\n",
    "|gpt-4o-audio-preview|$2.50|-|$10.00|\n",
    "|gpt-4o-mini-audio-preview|$0.15|-|$0.60|\n",
    "|o1|$15.00|$7.50|$60.00|\n",
    "|o1-pro|$150.00|-|$600.00|\n",
    "|o3-pro|$20.00|-|$80.00|\n",
    "|o3|$2.00|$0.50|$8.00|\n",
    "|o3-deep-research|$10.00|$2.50|$40.00|\n",
    "|o4-mini|$1.10|$0.275|$4.40|\n",
    "|o4-mini-deep-research|$2.00|$0.50|$8.00|\n",
    "|o3-mini|$1.10|$0.55|$4.40|\n",
    "|o1-mini|$1.10|$0.55|$4.40|\n",
    "|codex-mini-latest|$1.50|$0.375|$6.00|\n",
    "|gpt-5-search-api|$1.25|$0.125|$10.00|\n",
    "|gpt-4o-mini-search-preview|$0.15|-|$0.60|\n",
    "|gpt-4o-search-preview|$2.50|-|$10.00|\n",
    "|computer-use-preview|$3.00|-|$12.00|\n",
    "|gpt-image-1|$5.00|$1.25|-|\n",
    "|gpt-image-1-mini|$2.00|$0.20|-|\n",
    "\"\"\")\n",
    "\n",
    "# convert markdown table to data frame\n",
    "# Read table rows from markdown, parsing only lines that start with '|'\n",
    "with open(\"gpt_model_pricing.md\", \"r\") as f:\n",
    "    table_lines = [line for line in f if line.strip().startswith(\"|\")]\n",
    "\n",
    "# Combine into a single string and let pandas parse, removing unnamed columns\n",
    "table_str = \"\".join(table_lines)\n",
    "per_token_cost_df = pd.read_csv(\n",
    "    StringIO(table_str),\n",
    "    sep=\"|\",\n",
    "    engine=\"python\",\n",
    "    skipinitialspace=True\n",
    ").loc[:, lambda d: ~d.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Strip spaces from column names and all string values using map for all columns of object dtype\n",
    "per_token_cost_df.columns = per_token_cost_df.columns.str.strip()\n",
    "str_cols = per_token_cost_df.select_dtypes(include=\"object\").columns\n",
    "per_token_cost_df[str_cols] = per_token_cost_df[str_cols].map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# if model is \"---\" then drop the row\n",
    "per_token_cost_df = per_token_cost_df[per_token_cost_df['Model'] != '---']\n",
    "\n",
    "cols = [\"Input\", \"Cached input\", \"Output\"]\n",
    "per_token_cost_df[cols] = (\n",
    "    per_token_cost_df[cols]\n",
    "    .replace('[\\$,]', '', regex=True)     # remove $ and commas\n",
    "    .replace('-', '0', regex=False)       # optional: treat '-' as 0; or skip this line to get NaN\n",
    "    .apply(pd.to_numeric, errors='coerce')  # safely convert to float\n",
    ")\n",
    "\n",
    "# frame as cost per token; divide by 1M\n",
    "per_token_cost_df[['Input','Cached input','Output']] /= 1e6\n",
    "\n",
    "per_token_cost_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e841c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to calculate cost of prompt\n",
    "def calculate_prompt_cost(prompt: str, model: str) -> float:\n",
    "    # get the number of tokens in the prompt\n",
    "    num_tokens = num_tokens_in_prompt(prompt, model)[1]\n",
    "    # Ensure num_tokens is an integer (not str/array/etc.)\n",
    "    try:\n",
    "        num_tokens_int = int(num_tokens)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"num_tokens_in_prompt returned non-integer: {num_tokens!r}\") from e\n",
    "    # get the cost per token from the dataframe (get the scalar float, not a Series)\n",
    "    cost_per_token = per_token_cost_df.query(f'Model == \"{model}\"')['Input'].iloc[0]\n",
    "    # Ensure cost_per_token is a float\n",
    "    try:\n",
    "        cost_per_token = float(cost_per_token)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"per_token_cost_df returned non-numeric cost: {cost_per_token!r}\") from e\n",
    "    total_cost = num_tokens_int * cost_per_token\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Number of tokens: {num_tokens_int:,}\")\n",
    "    print(f\"Cost estimate: ${total_cost:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b18174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-5\n",
      "Number of tokens: 7\n",
      "Cost estimate: $0.00000875\n"
     ]
    }
   ],
   "source": [
    "calculate_prompt_cost(example_prompt, \"gpt-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1d643",
   "metadata": {},
   "source": [
    "### Readwise API: Get All Books with Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49de6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found existing df_books.csv. Loading from file...\n"
     ]
    }
   ],
   "source": [
    "# Future TODO: only get new books from the API and append to the existing df_books.csv\n",
    "# Future TODO: move to using a database instead of CSVs\n",
    " \n",
    "load_dotenv()\n",
    "token = os.getenv(\"READWISE_API_TOKEN\")\n",
    "headers = {\"Authorization\": f\"Token {token}\"}\n",
    "\n",
    "def fetch_books_by_category(category=\"books\", save_path='df_books.csv'):\n",
    "    url = \"https://readwise.io/api/v2/books/\"\n",
    "    params = {\"category\": category, \"page_size\": 100}\n",
    "    all_books = []\n",
    "\n",
    "    while url:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        all_books.extend(data[\"results\"])\n",
    "        url = data.get(\"next\")\n",
    "        params = None  # after first call, pagination URLs already include params\n",
    "\n",
    "    df_books = pd.DataFrame(all_books)\n",
    "\n",
    "    # generate a new column in df_books that is the concat of title and author\n",
    "    df_books['title_author'] = df_books['title'] + ' by ' + df_books['author']\n",
    "\n",
    "    # filter out row where title = Quick Passages\n",
    "    df_books = df_books[df_books['title'] != 'Quick Passages']\n",
    "\n",
    "    # Add save logic: only write to CSV if the file does not already exist\n",
    "    if not os.path.exists(save_path):\n",
    "        df_books.to_csv(save_path, index=False)\n",
    "    else:\n",
    "        print(f\"File '{save_path}' already exists.\")\n",
    "\n",
    "    return df_books\n",
    "\n",
    "if os.path.exists('df_books.csv'):\n",
    "    print(\"✅ Found existing df_books.csv. Loading from file...\")\n",
    "    df_books = pd.read_csv('df_books.csv')\n",
    "else:\n",
    "    df_books = fetch_books_by_category(\"books\")\n",
    "    print(f\"✅ Retrieved {len(df_books)} books.\")\n",
    "    print(df_books[[\"id\", \"title\", \"author\", \"num_highlights\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742044b",
   "metadata": {},
   "source": [
    "### OpenAI API: Book Categorization Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e60afd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found existing book_categorization.csv. Loading from working directory...\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('book_categorization.csv'):\n",
    "    print(\"✅ Found existing book_categorization.csv. Loading from working directory...\")\n",
    "    df_book_cats = pd.read_csv('book_categorization.csv')\n",
    "else:\n",
    "    load_dotenv()\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    titles_csv = df_books['title_author'].to_csv(index=False, header=True)\n",
    "\n",
    "    categorization_prompt = (\n",
    "        \"You are an expert librarian and literary classifier who categorizes books by their dominant subject area.\\n\"\n",
    "        \"Use your knowledge and, if necessary, live web search to determine accurate categories.\\n\\n\"\n",
    "        \"Return results in **CSV** format using `::` as the column separator with two columns:\\n\"\n",
    "        \"\\\"title_author\\\"::\\\"category\\\"\\n\\n\"\n",
    "        \"Choose **one** category per book from this list:\\n\"\n",
    "        \"- Business Strategy\\n\"\n",
    "        \"- Finance or Investing or Economics or Accounting\\n\"\n",
    "        \"- Building Product or Startups\\n\"\n",
    "        \"- Marketing or Sales\\n\"\n",
    "        \"- Leadership or Management\\n\"\n",
    "        \"- Data Analytics, Statistics, or AI\\n\"\n",
    "        \"- Self-Help or Motivational or Inspirational\\n\"\n",
    "        \"- Other\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1. Use the main theme or subject of the book (not keywords in the title).\\n\"\n",
    "        \"2. If a book clearly spans two areas, choose the most dominant.\\n\"\n",
    "        \"3. If no clear match, use \\\"Other\\\".\\n\"\n",
    "        \"4. Output only the CSV — no commentary, no markdown, no code block.\\n\\n\"\n",
    "        \"Here is the CSV input with the column \\\"title_author\\\":\\n\"\n",
    "        f\"{titles_csv}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-5\",\n",
    "            input=[{\"role\": \"user\", \"content\": categorization_prompt}],\n",
    "            tools=[{\"type\": \"web_search\"}],\n",
    "            tool_choice=\"auto\",\n",
    "            reasoning={\"effort\": \"medium\"}\n",
    "        )\n",
    "        categories_csv = response.output_text.strip()\n",
    "        df_book_cats = pd.read_csv(StringIO(categories_csv.replace(\"::\", \",\")), header=None, names=[\"title_author\", \"category\"])\n",
    "        df_book_cats.to_csv('book_categorization.csv', index=False)\n",
    "        print(\"=== BOOK CATEGORIZATION RESULTS ===\\n\", categories_csv)\n",
    "        print(\"\\n✅ Categorization completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error calling OpenAI API for book categorization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c62a8bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Self-Help or Motivational or Inspirational         46\n",
       "Data Analytics, Statistics, or AI                  35\n",
       "Leadership or Management                           19\n",
       "Other                                              16\n",
       "Finance or Investing or Economics or Accounting    15\n",
       "Marketing or Sales                                 14\n",
       "Building Product or Startups                       13\n",
       "Business Strategy                                   8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_book_cats['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ded6f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop category column from df_books; the category is book for all rows given filters above\n",
    "df_books.drop(columns=['category'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf69de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join agent categorization to main df_books data\n",
    "df_books_2 = df_books.merge(df_book_cats, on='title_author', how='left').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9befb",
   "metadata": {},
   "source": [
    "### Get Book Highlights from Marketing & Sales Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b08071f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get marketing and sales book ids\n",
    "# ids are a readwise id for a book\n",
    "marketing_ids = df_books_2.query('category == \"Marketing or Sales\"')['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0f56f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_readwise_highlights(book_ids):\n",
    "    \"\"\"\n",
    "    Given a list of Readwise book IDs, fetch all highlights and notes using the Readwise export API.\n",
    "\n",
    "    Args:\n",
    "        book_ids (list of int): List of numeric Readwise book IDs.\n",
    "\n",
    "    Returns:\n",
    "        list: List of book JSON objects from Readwise containing highlights and notes.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    token = os.getenv(\"READWISE_API_TOKEN\")\n",
    "    headers = {\"Authorization\": f\"Token {token}\"}\n",
    "    ids_param = \",\".join(str(i) for i in book_ids)\n",
    "    base_url = \"https://readwise.io/api/v2/export/\"\n",
    "\n",
    "    all_data = []\n",
    "    params = {\"ids\": ids_param}\n",
    "    next_page_cursor = None\n",
    "\n",
    "    while True:\n",
    "        if next_page_cursor:\n",
    "            params[\"pageCursor\"] = next_page_cursor\n",
    "        else:\n",
    "            params.pop(\"pageCursor\", None)\n",
    "\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "\n",
    "        # Use pandas to efficiently concatenate list of dicts if enough data accumulates\n",
    "        all_data.extend(result[\"results\"])\n",
    "        next_page_cursor = result.get(\"nextPageCursor\")\n",
    "\n",
    "        print(f\"📘 Retrieved {len(result['results'])} books in this page. \"\n",
    "              f\"Total so far: {len(all_data)}\")\n",
    "\n",
    "        if not next_page_cursor:\n",
    "            break  # no more pages\n",
    "\n",
    "    print(f\"✅ Finished fetching {len(all_data)} total books from Readwise export\")\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb8de3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_readwise_highlights(all_data):\n",
    "    \"\"\"\n",
    "    Flatten nested Readwise book highlight JSON into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        all_data (list): List of book JSON objects from Readwise containing highlights and notes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with highlights and book metadata flattened.\n",
    "    \"\"\"\n",
    "    df = pd.json_normalize(\n",
    "        all_data,\n",
    "        record_path=\"highlights\",\n",
    "        meta=[\"user_book_id\", \"title\", \"author\", \"category\"],\n",
    "        record_prefix=\"highlight_\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbe542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Retrieved 9 books in this page. Total so far: 9\n",
      "📘 Retrieved 5 books in this page. Total so far: 14\n",
      "✅ Finished fetching 14 total books from Readwise export\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlight_id</th>\n",
       "      <th>highlight_is_deleted</th>\n",
       "      <th>highlight_text</th>\n",
       "      <th>highlight_location</th>\n",
       "      <th>highlight_location_type</th>\n",
       "      <th>highlight_note</th>\n",
       "      <th>highlight_color</th>\n",
       "      <th>highlight_highlighted_at</th>\n",
       "      <th>highlight_created_at</th>\n",
       "      <th>highlight_updated_at</th>\n",
       "      <th>...</th>\n",
       "      <th>highlight_url</th>\n",
       "      <th>highlight_book_id</th>\n",
       "      <th>highlight_tags</th>\n",
       "      <th>highlight_is_favorite</th>\n",
       "      <th>highlight_is_discard</th>\n",
       "      <th>highlight_readwise_url</th>\n",
       "      <th>user_book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>948377431</td>\n",
       "      <td>False</td>\n",
       "      <td>ARPU is usually the annual revenue that a comp...</td>\n",
       "      <td>201</td>\n",
       "      <td>location</td>\n",
       "      <td></td>\n",
       "      <td>yellow</td>\n",
       "      <td>2025-10-16T04:56:00Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>55650413</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://readwise.io/open/948377431</td>\n",
       "      <td>55650413</td>\n",
       "      <td>Click Here</td>\n",
       "      <td>Alex Schultz</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>948377432</td>\n",
       "      <td>False</td>\n",
       "      <td>Choosing the right channel means asking yourse...</td>\n",
       "      <td>203</td>\n",
       "      <td>location</td>\n",
       "      <td>And at what cost and scale</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2025-10-16T04:56:00Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>55650413</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://readwise.io/open/948377432</td>\n",
       "      <td>55650413</td>\n",
       "      <td>Click Here</td>\n",
       "      <td>Alex Schultz</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>948377433</td>\n",
       "      <td>False</td>\n",
       "      <td>A CRU is a user who has registered and then co...</td>\n",
       "      <td>213</td>\n",
       "      <td>location</td>\n",
       "      <td></td>\n",
       "      <td>yellow</td>\n",
       "      <td>2025-10-16T04:56:00Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>55650413</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://readwise.io/open/948377433</td>\n",
       "      <td>55650413</td>\n",
       "      <td>Click Here</td>\n",
       "      <td>Alex Schultz</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>948377434</td>\n",
       "      <td>False</td>\n",
       "      <td>DSPs arrived in the 2010s to simplify ad buyin...</td>\n",
       "      <td>221</td>\n",
       "      <td>location</td>\n",
       "      <td>Whags the back story? Do dsp aggregate demand?</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2025-10-16T04:56:00Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>55650413</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://readwise.io/open/948377434</td>\n",
       "      <td>55650413</td>\n",
       "      <td>Click Here</td>\n",
       "      <td>Alex Schultz</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>948377435</td>\n",
       "      <td>False</td>\n",
       "      <td>eCPM is a metric that estimates how much an ad...</td>\n",
       "      <td>225</td>\n",
       "      <td>location</td>\n",
       "      <td>Wherfe is this used</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2025-10-16T04:56:00Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>2025-10-16T05:02:56.015Z</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>55650413</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://readwise.io/open/948377435</td>\n",
       "      <td>55650413</td>\n",
       "      <td>Click Here</td>\n",
       "      <td>Alex Schultz</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   highlight_id  highlight_is_deleted  \\\n",
       "0     948377431                 False   \n",
       "1     948377432                 False   \n",
       "2     948377433                 False   \n",
       "3     948377434                 False   \n",
       "4     948377435                 False   \n",
       "\n",
       "                                      highlight_text  highlight_location  \\\n",
       "0  ARPU is usually the annual revenue that a comp...                 201   \n",
       "1  Choosing the right channel means asking yourse...                 203   \n",
       "2  A CRU is a user who has registered and then co...                 213   \n",
       "3  DSPs arrived in the 2010s to simplify ad buyin...                 221   \n",
       "4  eCPM is a metric that estimates how much an ad...                 225   \n",
       "\n",
       "  highlight_location_type                                  highlight_note  \\\n",
       "0                location                                                   \n",
       "1                location                      And at what cost and scale   \n",
       "2                location                                                   \n",
       "3                location  Whags the back story? Do dsp aggregate demand?   \n",
       "4                location                             Wherfe is this used   \n",
       "\n",
       "  highlight_color highlight_highlighted_at      highlight_created_at  \\\n",
       "0          yellow     2025-10-16T04:56:00Z  2025-10-16T05:02:56.015Z   \n",
       "1          yellow     2025-10-16T04:56:00Z  2025-10-16T05:02:56.015Z   \n",
       "2          yellow     2025-10-16T04:56:00Z  2025-10-16T05:02:56.015Z   \n",
       "3          yellow     2025-10-16T04:56:00Z  2025-10-16T05:02:56.015Z   \n",
       "4          yellow     2025-10-16T04:56:00Z  2025-10-16T05:02:56.015Z   \n",
       "\n",
       "       highlight_updated_at  ... highlight_url highlight_book_id  \\\n",
       "0  2025-10-16T05:02:56.015Z  ...          None          55650413   \n",
       "1  2025-10-16T05:02:56.015Z  ...          None          55650413   \n",
       "2  2025-10-16T05:02:56.015Z  ...          None          55650413   \n",
       "3  2025-10-16T05:02:56.015Z  ...          None          55650413   \n",
       "4  2025-10-16T05:02:56.015Z  ...          None          55650413   \n",
       "\n",
       "  highlight_tags  highlight_is_favorite highlight_is_discard  \\\n",
       "0             []                  False                False   \n",
       "1             []                  False                False   \n",
       "2             []                  False                False   \n",
       "3             []                  False                False   \n",
       "4             []                  False                False   \n",
       "\n",
       "               highlight_readwise_url  user_book_id       title        author  \\\n",
       "0  https://readwise.io/open/948377431      55650413  Click Here  Alex Schultz   \n",
       "1  https://readwise.io/open/948377432      55650413  Click Here  Alex Schultz   \n",
       "2  https://readwise.io/open/948377433      55650413  Click Here  Alex Schultz   \n",
       "3  https://readwise.io/open/948377434      55650413  Click Here  Alex Schultz   \n",
       "4  https://readwise.io/open/948377435      55650413  Click Here  Alex Schultz   \n",
       "\n",
       "  category  \n",
       "0    books  \n",
       "1    books  \n",
       "2    books  \n",
       "3    books  \n",
       "4    books  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rw_highlights = fetch_readwise_highlights(marketing_ids)\n",
    "\n",
    "rw_hl_df = flatten_readwise_highlights(raw_rw_highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "989a547e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlight_text</th>\n",
       "      <th>title_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARPU is usually the annual revenue that a comp...</td>\n",
       "      <td>Click Here by Alex Schultz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Choosing the right channel means asking yourse...</td>\n",
       "      <td>Click Here by Alex Schultz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A CRU is a user who has registered and then co...</td>\n",
       "      <td>Click Here by Alex Schultz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSPs arrived in the 2010s to simplify ad buyin...</td>\n",
       "      <td>Click Here by Alex Schultz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eCPM is a metric that estimates how much an ad...</td>\n",
       "      <td>Click Here by Alex Schultz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      highlight_text  \\\n",
       "0  ARPU is usually the annual revenue that a comp...   \n",
       "1  Choosing the right channel means asking yourse...   \n",
       "2  A CRU is a user who has registered and then co...   \n",
       "3  DSPs arrived in the 2010s to simplify ad buyin...   \n",
       "4  eCPM is a metric that estimates how much an ad...   \n",
       "\n",
       "                 title_author  \n",
       "0  Click Here by Alex Schultz  \n",
       "1  Click Here by Alex Schultz  \n",
       "2  Click Here by Alex Schultz  \n",
       "3  Click Here by Alex Schultz  \n",
       "4  Click Here by Alex Schultz  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only columns needed for synthesis\n",
    "highlights_slim = rw_hl_df[['title', 'author', 'highlight_text']].copy()\n",
    "\n",
    "# concat title and author\n",
    "highlights_slim['title_author'] = highlights_slim['title'] + ' by ' + highlights_slim['author']\n",
    "\n",
    "# drop title and author\n",
    "highlights_slim.drop(columns=['title', 'author'], inplace=True)\n",
    "\n",
    "# filter to only include title_author instances with 30 or more highlights\n",
    "highlights_to_synthesize = (\n",
    "    highlights_slim\n",
    "    # window function type logic to get number of highlights per book\n",
    "    .assign(count=lambda d: d['title_author'].map(d['title_author'].value_counts()))\n",
    "    # if count is 30 or more, keep the row else drop it\n",
    "    .query('count >= 30')\n",
    "    # drop the count helper column\n",
    "    .drop(columns='count')\n",
    ")\n",
    "\n",
    "highlights_to_synthesize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d84edfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_author\n",
       "Hacking Growth by Sean Ellis and Morgan Brown               318\n",
       "Ogilvy on Advertising by David Ogilvy                       157\n",
       "Converted by Neil Hoyne                                      86\n",
       "Hook Point by Brendan  Kane                                  81\n",
       "Click Here by Alex Schultz                                   62\n",
       "Everybody Writes by Ann Handley                              51\n",
       "Retention Point by Robert Skrob                              42\n",
       "Audience-Ology by Kevin Goetz                                42\n",
       "Growth Hacker Marketing by Ryan Holiday                      41\n",
       "Monetizing Innovation by Madhavan Ramanujam, Georg Tacke     31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlights_to_synthesize['title_author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628ad11",
   "metadata": {},
   "source": [
    "### OpenAI API: Summarize Key Ideas Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74df922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from textwrap import dedent\n",
    "\n",
    "def build_key_ideas_prompt(book_data, focus_instructions):\n",
    "    \"\"\"\n",
    "    Build the structured prompt for the Key Ideas Agent.\n",
    "\n",
    "    Args:\n",
    "        book_data (dict): Dictionary containing book metadata and highlights.\n",
    "            Example:\n",
    "            {\n",
    "              \"title_author\": \"Click Here by Alex Schultz\",\n",
    "              \"category\": \"Marketing or Sales\",\n",
    "              \"highlights\": [\n",
    "                {\"highlight_id\": 1, \"text\": \"ARPU is annual revenue per user.\"},\n",
    "                {\"highlight_id\": 2, \"text\": \"Choosing the right channel...\"}\n",
    "              ]\n",
    "            }\n",
    "        focus_instructions (str): Guidance for what highlights to emphasize,\n",
    "            e.g. \"Focus on fundamental ideas to marketing such as positioning and targeting.\"\n",
    "\n",
    "    Returns:\n",
    "        str: Complete formatted prompt ready for the OpenAI API.\n",
    "    \"\"\"\n",
    "    title_author = book_data[\"title_author\"]\n",
    "    highlights_json = json.dumps(book_data[\"highlights\"], indent=2)\n",
    "\n",
    "    prompt = dedent(f\"\"\"\n",
    "    You are the Key Ideas Agent.\n",
    "\n",
    "    Your goal is to extract and summarize the key ideas from this book’s highlights.\n",
    "    You must focus entirely on what is expressed in the highlights.\n",
    "    If a highlight is incomplete or lacks context, you may perform a light web search\n",
    "    to fill missing definitions or clarify references — but never introduce new ideas\n",
    "    not grounded in the highlights.\n",
    "\n",
    "    ### 🧭 Focus\n",
    "    {focus_instructions}\n",
    "\n",
    "    ### Book Information\n",
    "    - Title & Author: {title_author}\n",
    "\n",
    "    ### Highlights\n",
    "    {highlights_json}\n",
    "\n",
    "    ### 🧩 Task\n",
    "    1. Extract the main conceptual ideas found within these highlights.\n",
    "    2. Ground every idea in one or more highlight_ids.\n",
    "    3. Output valid JSON exactly following this schema:\n",
    "\n",
    "    {{\n",
    "      \"book\": {{\n",
    "        \"title_author\": \"string\"\n",
    "      }},\n",
    "      \"focus\": \"string\",\n",
    "      \"key_ideas\": [\n",
    "        {{\n",
    "          \"id\": \"string\",\n",
    "          \"title\": \"string\",\n",
    "          \"definition\": \"string\",\n",
    "          \"supporting_highlights\": [\n",
    "            {{\n",
    "              \"highlight_id\": \"integer\",\n",
    "              \"text\": \"string\",\n",
    "              \"note\": \"string | null\"\n",
    "            }}\n",
    "          ],\n",
    "          \"web_context\": [\n",
    "            {{\n",
    "              \"source_url\": \"string\",\n",
    "              \"context_summary\": \"string\"\n",
    "            }}\n",
    "          ]\n",
    "        }}\n",
    "      ],\n",
    "      \"agent_summary\": {{\n",
    "        \"summary_text\": \"string\",\n",
    "        \"highlight_count\": \"integer\",\n",
    "        \"token_estimates\": {{\n",
    "          \"input_tokens\": \"integer\",\n",
    "          \"output_tokens\": \"integer\"\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "205f4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_book_json(df: pd.DataFrame):\n",
    "    \"\"\"Convert DataFrame of highlights into JSON grouped by book.\"\"\"\n",
    "    books = []\n",
    "    for title_author, group in df.groupby(\"title_author\"):\n",
    "        highlights = [\n",
    "            {\"highlight_id\": i + 1, \"text\": text}\n",
    "            for i, text in enumerate(group[\"highlight_text\"])\n",
    "        ]\n",
    "        books.append({\"title_author\": title_author, \"highlights\": highlights})\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79509411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_marketing_prompt(book_title_author, highlights_df, focus_instructions=None):\n",
    "    \"\"\"\n",
    "    Generate a prompt for the Key Ideas Agent based on book input.\n",
    "\n",
    "    Args:\n",
    "        book_title_author (str): The combined 'title_author' string for the target book.\n",
    "        highlights_df (pd.DataFrame): DataFrame containing highlight data.\n",
    "        focus_instructions (str, optional): Instructions for what to focus on in the prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated prompt text.\n",
    "    \"\"\"\n",
    "    if focus_instructions is None:\n",
    "        focus_instructions = (\n",
    "            \"Focus on fundamental ideas to marketing. Help folks new to marketing understand the core ideas of marketing.\"\n",
    "        )\n",
    "    book_json = df_to_book_json(highlights_df.query(f'title_author == \"{book_title_author}\"'))[0]\n",
    "    prompt_text = build_key_ideas_prompt(book_json, focus_instructions)\n",
    "    return prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d95cfea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_marketing_prompts_for_all_books(highlights_df: pd.DataFrame, focus_instructions: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Run generate_marketing_prompt and call GPT for each unique book in the DataFrame.\n",
    "    Returns a dictionary mapping title_author → response text (or structured JSON if applicable).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Initialization ---\n",
    "    load_dotenv()\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    results = {}\n",
    "\n",
    "    if highlights_df.empty:\n",
    "        print(\"⚠️ No highlights found. Exiting early.\")\n",
    "        return results\n",
    "\n",
    "    # --- Group by book for cleaner iteration ---\n",
    "    for title_author, group in highlights_df.groupby(\"title_author\", sort=False):\n",
    "        print(f\"📘 Processing book: {title_author} ({len(group)} highlights)\")\n",
    "\n",
    "        try:\n",
    "            # Build prompt once per book\n",
    "            prompt = generate_marketing_prompt(title_author, group, focus_instructions)\n",
    "\n",
    "            # Make model call\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-5-mini\",\n",
    "                input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                tools=[{\"type\": \"web_search\"}],\n",
    "                tool_choice=\"auto\",\n",
    "                reasoning={\"effort\": \"low\"}\n",
    "            )\n",
    "\n",
    "            # Parse structured JSON if valid, else fallback to text\n",
    "            try:\n",
    "                results[title_author] = json.loads(response.output_text)\n",
    "            except json.JSONDecodeError:\n",
    "                results[title_author] = {\"raw_text\": response.output_text}\n",
    "\n",
    "            print(f\"✅ Completed summary for: {title_author}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing '{title_author}': {e}\")\n",
    "            results[title_author] = {\"error\": str(e)}\n",
    "\n",
    "    print(f\"\\n🏁 Completed all books ({len(results)} processed).\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5fb63785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Processing book: Click Here by Alex Schultz (62 highlights)\n",
      "✅ Completed summary for: Click Here by Alex Schultz\n",
      "📘 Processing book: Ogilvy on Advertising by David Ogilvy (157 highlights)\n",
      "✅ Completed summary for: Ogilvy on Advertising by David Ogilvy\n",
      "📘 Processing book: Retention Point by Robert Skrob (42 highlights)\n",
      "✅ Completed summary for: Retention Point by Robert Skrob\n",
      "📘 Processing book: Growth Hacker Marketing by Ryan Holiday (41 highlights)\n",
      "✅ Completed summary for: Growth Hacker Marketing by Ryan Holiday\n",
      "📘 Processing book: Hacking Growth by Sean Ellis and Morgan Brown (318 highlights)\n",
      "✅ Completed summary for: Hacking Growth by Sean Ellis and Morgan Brown\n",
      "📘 Processing book: Monetizing Innovation by Madhavan Ramanujam, Georg Tacke (31 highlights)\n",
      "✅ Completed summary for: Monetizing Innovation by Madhavan Ramanujam, Georg Tacke\n",
      "📘 Processing book: Audience-Ology by Kevin Goetz (42 highlights)\n",
      "✅ Completed summary for: Audience-Ology by Kevin Goetz\n",
      "📘 Processing book: Everybody Writes by Ann Handley (51 highlights)\n",
      "✅ Completed summary for: Everybody Writes by Ann Handley\n",
      "📘 Processing book: Hook Point by Brendan  Kane (81 highlights)\n",
      "✅ Completed summary for: Hook Point by Brendan  Kane\n",
      "📘 Processing book: Converted by Neil Hoyne (86 highlights)\n",
      "✅ Completed summary for: Converted by Neil Hoyne\n",
      "\n",
      "🏁 Completed all books (10 processed).\n"
     ]
    }
   ],
   "source": [
    "focus_instructions = (\n",
    "    \"Focus on fundamental ideas to marketing.\"\n",
    "    \"Help folks new to marketing understand the core ideas of marketing.\"\n",
    ")\n",
    "\n",
    "key_ideas_results = run_marketing_prompts_for_all_books(highlights_to_synthesize, focus_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144897c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def save_json_results(results: dict, prefix: str = \"results\"):\n",
    "    \"\"\"\n",
    "    Save a dictionary as a timestamped JSON file in the working directory.\n",
    "\n",
    "    Args:\n",
    "        results (dict): Dictionary of outputs to save.\n",
    "        prefix (str): Optional filename prefix. Defaults to 'results'.\n",
    "\n",
    "    Returns:\n",
    "        Path: The full path to the saved JSON file.\n",
    "    \"\"\"\n",
    "    name = input(\"Enter your name (for file naming, optional): \").strip()\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_prefix = f\"{prefix}_{name}\" if name else prefix\n",
    "    filename = f\"{file_prefix}_{timestamp}.json\"\n",
    "    path = Path.cwd() / filename\n",
    "\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"💾 Saved results to {path.resolve()}\")\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77f9c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved results to /Users/brianmoore/Documents/GitHub/kindle_eda/key_ideas_results_20251026_091658.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/brianmoore/Documents/GitHub/kindle_eda/key_ideas_results_20251026_091658.json')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_json_results(key_ideas_results, 'key_ideas_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5f5a8",
   "metadata": {},
   "source": [
    "### OpenAI API: First Principles Agent Based on Key Ideas by Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a6b8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_first_principles_agent_from_key_ideas(key_ideas_results: dict, focus_instructions: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Generate cross-book first principles from multiple Key Ideas Agent outputs using GPT-5.\n",
    "    Uses light web search for incomplete context and returns structured JSON.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # Normalize to parsed dicts containing key_ideas\n",
    "    key_ideas_jsons = []\n",
    "    for book, result in key_ideas_results.items():\n",
    "        try:\n",
    "            if isinstance(result, str):\n",
    "                result = json.loads(result)\n",
    "            if \"key_ideas\" in result:\n",
    "                key_ideas_jsons.append(result)\n",
    "        except Exception:\n",
    "            print(f\"⚠️ Skipping invalid entry: {book}\")\n",
    "\n",
    "    if not key_ideas_jsons:\n",
    "        raise ValueError(\"No valid Key Ideas JSON found.\")\n",
    "\n",
    "    focus = focus_instructions or (\n",
    "        \"Synthesize the first principle marketing ideas from the books below.\"\n",
    "    )\n",
    "\n",
    "    # Compact prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are the First Principles Agent.\n",
    "\n",
    "    Goal: Derive timeless, cross-book first principles from the ideas below.\n",
    "    Each object represents one book's key ideas on a shared theme.\n",
    "    Use web search lightly to fill missing context, not expand scope.\n",
    "\n",
    "    Focus: {focus}\n",
    "\n",
    "    Input:\n",
    "    {json.dumps(key_ideas_jsons, indent=2)}\n",
    "\n",
    "    Output valid JSON:\n",
    "    {{\n",
    "    \"first_principles\": [\n",
    "        {{\n",
    "        \"principle_id\": \"string\",\n",
    "        \"principle_title\": \"string\",\n",
    "        \"definition\": \"string\",\n",
    "        \"derived_from_books\": [\"string\"],\n",
    "        \"supporting_ideas\": [\"string\"]\n",
    "        }}\n",
    "    ],\n",
    "    \"meta\": {{\n",
    "        \"books_processed\": \"integer\",\n",
    "        \"total_key_ideas\": \"integer\",\n",
    "        \"generated_at\": \"YYYY-MM-DD\"\n",
    "    }}\n",
    "    }}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    print(f\"🧠 Synthesizing first principles from {len(key_ideas_jsons)} books...\")\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5\",\n",
    "        input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        tools=[{\"type\": \"web_search\"}],\n",
    "        tool_choice=\"auto\",\n",
    "        reasoning={\"effort\": \"low\"}\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        return json.loads(response.output_text)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"raw_text\": response.output_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d933b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Synthesizing first principles from 10 books...\n"
     ]
    }
   ],
   "source": [
    "fp_results = run_first_principles_agent_from_key_ideas(key_ideas_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dad0123c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved results to /Users/brianmoore/Documents/GitHub/kindle_eda/fp_results_20251026_091710.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/brianmoore/Documents/GitHub/kindle_eda/fp_results_20251026_091710.json')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save fp_results to a json file\n",
    "save_json_results(fp_results, 'fp_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "95991d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### FP1 — Start with a must‑have product and a clear promise\n",
      "- Description: Marketing cannot compensate for a product people don’t truly want. Build or refine until the core value is obvious, then articulate a specific, customer-important promise the product reliably delivers.\n",
      "- Source Books: Hacking Growth by Sean Ellis and Morgan Brown, Growth Hacker Marketing — Ryan Holiday, Ogilvy on Advertising by David Ogilvy\n",
      "- Example: Slack pivoted from the failed game Glitch to a must‑have team messaging tool and led with the plainspoken strapline “Be less busy,” a clear promise that resonated with early adopters and enterprises alike. ([marketingweek.com](https://www.marketingweek.com/disruptive-brands/slack/?utm_source=openai))\n",
      "\n",
      "### FP2 — Make the customer’s outcome the North Star\n",
      "- Description: Define a single, ambitious goal and metric that represent the customer outcome you exist to create; align revenue and tactics to serve that outcome and reject efforts that trade it off.\n",
      "- Source Books: Click Here by Alex Schultz, Converted by Neil Hoyne, Everybody Writes — Ann Handley\n",
      "- Example: Airbnb organizes around “Nights and Experiences Booked” as a central metric, reporting it prominently in shareholder letters and aligning teams on improving guest/host outcomes that drive this measure. ([sec.gov](https://www.sec.gov/Archives/edgar/data/1559720/000119312525026054/d915198dex991.htm?utm_source=openai))\n",
      "\n",
      "### FP3 — Prove incrementality and optimize for lifetime value\n",
      "- Description: Judge marketing by incremental impact and long-term customer value, not by activity or short-term transactions; spend more where you can prove true lift and higher lifetime value.\n",
      "- Source Books: Click Here by Alex Schultz, Converted by Neil Hoyne\n",
      "- Example: After cutting performance marketing in 2020, Airbnb saw traffic rebound to ~95% of prior levels, then permanently shifted spend toward brand and higher‑return channels—an explicit bet on incremental impact and LTV. ([cnbc.com](https://www.cnbc.com/2021/04/16/cnbc-exclusive-cnbc-transcript-airbnb-co-founder-ceo-brian-chesky-speaks-with-cnbcs-techcheck-today.html?utm_source=openai))\n",
      "\n",
      "### FP4 — Price and product design should be led by willingness to pay\n",
      "- Description: Discover what customers value and will pay before you finalize features. Segment by needs/value/WTP and build offers and prices for the highest-opportunity segment.\n",
      "- Source Books: Monetizing Innovation by Madhavan Ramanujam, Georg Tacke\n",
      "- Example: Superhuman used Van Westendorp willingness‑to‑pay surveys (inspired by Monetizing Innovation) to set premium pricing around $30/month and reinforce a “premium email” positioning. ([techcrunch.com](https://techcrunch.com/2020/06/18/superhumans-rahul-vohra-says-recession-is-the-perfect-time-to-be-aggressive-for-well-capitalized-startups/?utm_source=openai))\n",
      "\n",
      "### FP5 — Clarity beats cleverness: promise, prove, and be specific\n",
      "- Description: State a concrete benefit in simple, specific language; show how the product delivers it; write for one reader with empathy and utility.\n",
      "- Source Books: Ogilvy on Advertising by David Ogilvy, Everybody Writes — Ann Handley\n",
      "- Example: Stripe’s home and newsroom consistently describe it as “the financial infrastructure platform for businesses”—a crisp promise that helps prospects instantly grasp what Stripe does. ([stripe.com](https://stripe.com/newsroom/news/stripe-2024-update?utm_source=openai))\n",
      "\n",
      "### FP6 — Shorten the path to value\n",
      "- Description: Reduce friction and time between a prospect’s first touch and their ‘aha’/conversion, but retain the steps essential to a quality outcome. Design onboarding for a fast, meaningful first win.\n",
      "- Source Books: Click Here by Alex Schultz, Hacking Growth by Sean Ellis and Morgan Brown, Retention Point by Robert Skrob\n",
      "- Example: Facebook famously focused activation on helping new users add “7 friends in 10 days,” a simple rule that accelerated the first meaningful value moment and predicted retention. ([ma.tt](https://ma.tt/2016/03/chamath-on-growing-facebook/))\n",
      "\n",
      "### FP7 — Retention is the business model\n",
      "- Description: Shift the finish line from acquisition to durable retention; identify the moment customers become long-term (‘Retention Point’/stored value) and engineer the journey to reach it sooner.\n",
      "- Source Books: Retention Point by Robert Skrob, Hacking Growth by Sean Ellis and Morgan Brown\n",
      "- Example: Duolingo’s streak mechanics (and tools like Streak Freeze) make daily practice sticky; the company highlights how streak protection improves experience and helps keep learners coming back. ([blog.duolingo.com](https://blog.duolingo.com/protecting-streaks-from-site-issues/?utm_source=openai))\n",
      "\n",
      "### FP8 — Measure what matters and measure it twice\n",
      "- Description: Instrument the full funnel with reliable, redundant logging; define what counts as ‘active’; monitor discrepancies; and use funnels, cohorts, and growth accounting to find the biggest opportunities.\n",
      "- Source Books: Click Here by Alex Schultz, Hacking Growth by Sean Ellis and Morgan Brown\n",
      "- Example: Social Capital popularized “growth accounting” (new + resurrected − churned) and the “quick ratio” to dissect active‑user growth beyond vanity metrics—practices many Bay Area teams adopted. ([medium.com](https://medium.com/swlh/diligence-at-social-capital-part-1-accounting-for-user-growth-4a8a449fddfc?utm_source=openai))\n",
      "\n",
      "### FP9 — Learn faster than the market\n",
      "- Description: Build a cross-functional growth system that runs high-velocity, minimum‑viable tests, prioritizes by Impact/Confidence/Ease, captures learnings, and mixes bold bets with steady optimizations.\n",
      "- Source Books: Hacking Growth by Sean Ellis and Morgan Brown, Growth Hacker Marketing — Ryan Holiday, Converted by Neil Hoyne\n",
      "- Example: Microsoft’s Bing runs hundreds of concurrent controlled experiments daily—embedding trustworthy A/B testing to speed decisions and compound ROI. ([blogs.bing.com](https://blogs.bing.com/search-quality-insights/August-2013/Large-Scale-Experimentation-at-Bing?utm_source=openai))\n",
      "\n",
      "### FP10 — Attention is scarce: earn it with strong hooks and immediate relevance\n",
      "- Description: Win the first seconds with a distinctive, concise hook that sets a clear expectation and ties to an outcome the audience wants; package for the platform (titles, thumbnails, pacing).\n",
      "- Source Books: Hook Point by Brendan Kane, Ogilvy on Advertising by David Ogilvy\n",
      "- Example: Coinbase’s 60‑second Super Bowl spot was just a bouncing QR code; it drew huge instant engagement and even crashed the site from traffic spikes. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Super_Bowl_commercials?utm_source=openai))\n",
      "\n",
      "### FP11 — Build growth into the product (ethically)\n",
      "- Description: Make sharing and referral a valuable, easy part of the experience using honest incentives and habit-forming triggers; avoid dark patterns; focus on viral loop quality over spam.\n",
      "- Source Books: Hacking Growth by Sean Ellis and Morgan Brown, Growth Hacker Marketing — Ryan Holiday\n",
      "- Example: Dropbox’s built‑in, two‑sided referral program permanently lifted sign‑ups and generated millions of invites per month—textbook product‑embedded growth. ([startup-marketing.com](https://www.startup-marketing.com/dropbox-the-model-%E2%80%9Cvalue-based%E2%80%9D-startup/?utm_source=openai))\n",
      "\n",
      "### FP12 — Focus beats spread: concentrate on high‑leverage channels and audiences\n",
      "- Description: Target early adopters where they gather and pour effort into one or two channels that show clear traction before layering others.\n",
      "- Source Books: Hacking Growth by Sean Ellis and Morgan Brown, Growth Hacker Marketing — Ryan Holiday\n",
      "- Example: Facebook started by focusing narrowly on Harvard and then Ivy League campuses before broadening access—concentrating efforts where network effects would ignite. ([history.com](https://www.history.com/this-day-in-history/facebook-launches-mark-zuckerberg?utm_source=openai))\n",
      "\n",
      "### FP13 — Audience truth > internal opinion\n",
      "- Description: Use well-designed audience testing and rapid research to inform creative and product decisions; synthesize feedback quickly into prioritized fixes; let paying audiences validate direction.\n",
      "- Source Books: Audience-Ology by Kevin Goetz\n",
      "- Example: Google’s culture famously tested even “41 shades of blue” to choose link colors, privileging user response over internal taste in UI decisions. ([wired.com](https://www.wired.com/2009/03/googles-data-cu/?utm_source=openai))\n",
      "\n",
      "### FP14 — Creativity serves sales and experience\n",
      "- Description: Judge creative by its ability to sell without taxing user experience; when you find a winner, keep it running and iterate rather than changing for taste alone.\n",
      "- Source Books: Ogilvy on Advertising by David Ogilvy, Click Here by Alex Schultz\n",
      "- Example: Apple’s long‑running “Get a Mac” campaign correlated with sizable sales lifts shortly after launch, so the company kept iterating on the winning creative over multiple years. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Get_a_Mac?utm_source=openai))\n",
      "\n",
      "### FP15 — Write to think and align teams\n",
      "- Description: Use writing (press releases, FAQs, narrative memos, clear copy) to force clarity, anticipate objections, and align product, marketing, and operations around the customer’s job‑to‑be‑done.\n",
      "- Source Books: Everybody Writes — Ann Handley, Growth Hacker Marketing — Ryan Holiday\n",
      "- Example: Amazon bans slide decks in favor of six‑page narrative memos and PR/FAQ docs; meetings start with silent reading to create shared context and sharper decisions. ([a16z.com](https://a16z.com/podcast/amazon-narratives-memos-working-backwards-from-release-more/?utm_source=openai))\n",
      "\n",
      "### FP16 — Respect cognitive load: simplify and guide\n",
      "- Description: Confusion and overwhelm kill action. Present the next best step, reduce choices and effort early, and teach what to do and what to believe to sustain momentum.\n",
      "- Source Books: Retention Point by Robert Skrob, Hacking Growth by Sean Ellis and Morgan Brown, Everybody Writes — Ann Handley\n",
      "- Example: Stripe reports businesses moving to its optimized Checkout/Payment Element saw an average 10.5% revenue uplift, reflecting many small simplifications that reduce friction and guidance gaps. ([stripe.com](https://stripe.com/newsroom/news/payments-revenue-uplift?utm_source=openai))\n",
      "\n",
      "### FP17 — Operational integrity of data is non‑negotiable\n",
      "- Description: Redundant instrumentation, clear definitions, discrepancy monitoring, and accounting for post‑transaction adjustments are prerequisites to trustworthy decisions and optimization.\n",
      "- Source Books: Click Here by Alex Schultz, Converted by Neil Hoyne\n",
      "- Example: Microsoft and others publish checklists and methods for trustworthy online experiments, warning how telemetry loss and logging issues can bias results without rigorous safeguards. ([microsoft.com](https://www.microsoft.com/en-us/research/publication/three-key-checklists-and-remedies-for-trustworthy-analysis-of-online-controlled-experiments-at-scale/?locale=zh-cn&utm_source=openai))\n",
      "\n",
      "### FP18 — Invest with discipline: back winners, cut losers, and budget exploration\n",
      "- Description: Concentrate spend on proven performers (channels, offers, products), stop what doesn’t work, and protect a fixed exploration budget to keep discovering new growth.\n",
      "- Source Books: Ogilvy on Advertising by David Ogilvy, Hacking Growth by Sean Ellis and Morgan Brown, Converted by Neil Hoyne\n",
      "- Example: Airbnb’s leadership described a permanent shift away from heavy performance marketing toward brand and high‑return levers—tightening ROI thresholds while still using performance as a targeted “laser.” ([marketingweek.com](https://www.marketingweek.com/airbnb-cfo-performance-brand/?utm_source=openai))\n",
      "\n",
      "Meta\n",
      "- Books processed: 10\n",
      "- Total key ideas: 102\n",
      "- Generated at: 2025-10-26\n"
     ]
    }
   ],
   "source": [
    "# generate prompt to format fp_results into a markdown list\n",
    "fp_prompt = f\"\"\"\n",
    "Format the following first principles json into a markdown list. \n",
    "{json.dumps(fp_results, indent=2)}\n",
    "\n",
    "Use the following format for each first principle:\n",
    "### <First Principle JSON>\n",
    "- Description: <Definition>\n",
    "- Source Books: <Derived from>\n",
    "- Example: <insert notable example from silicon valley>\n",
    "\n",
    "Use light web search to find example story of the first principle in action. Limit to 1 or 2 sentences.\n",
    "Do not change or text related to first principle, definition, or source books.\n",
    "\"\"\"\n",
    "\n",
    "# make openAI call to format fp_results into a markdown list\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=[{\"role\": \"user\", \"content\": fp_prompt}],\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    tool_choice=\"auto\",\n",
    "    reasoning={\"effort\": \"medium\"}\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "33b17d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save response.output_text to a markdown file\n",
    "# add timestamp to filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "with open(f'fp_results_{timestamp}.md', 'w') as f:\n",
    "    f.write(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961e1b2",
   "metadata": {},
   "source": [
    "### OpenAI API: Generate Short Summary for Each Book Referenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1fc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Describe each book and author in 1-2 sentences. Output in a markdown list.\\nClick Here by Alex Schultz\\nOgilvy on Advertising by David Ogilvy\\nRetention Point by Robert Skrob\\nGrowth Hacker Marketing by Ryan Holiday\\nHacking Growth by Sean Ellis and Morgan Brown\\nMonetizing Innovation by Madhavan Ramanujam, Georg Tacke\\nAudience-Ology by Kevin Goetz\\nEverybody Writes by Ann Handley\\nHook Point by Brendan  Kane\\nConverted by Neil Hoyne'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_titles = \"\\n\".join(highlights_to_synthesize['title_author'].unique())\n",
    "book_summary_prompt = (\n",
    "    \"Describe each book and author in 1-2 sentences. Output in a markdown list.\\n\"\n",
    "    f\"{book_titles}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81081d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Click Here — Alex Schultz  \n",
      "  A practical guide by Facebook growth leader Alex Schultz that explains data-driven experimentation, A/B testing, and metrics strategies for scaling product engagement and growth. It blends case studies with tactical advice for using analytics to drive user acquisition and retention.\n",
      "\n",
      "- Ogilvy on Advertising — David Ogilvy  \n",
      "  A classic handbook from advertising pioneer David Ogilvy that combines timeless principles of creative strategy, brand building, and campaign management with real-world examples and witty industry insight. It emphasizes research, clarity, and the primacy of the consumer in effective ad work.\n",
      "\n",
      "- Retention Point — Robert Skrob  \n",
      "  Focused on the economics of customer retention, Robert Skrob’s book outlines systems and metrics to increase lifetime customer value by reducing churn and improving onboarding, service, and follow-up. It provides actionable processes for turning one-time buyers into repeat customers.\n",
      "\n",
      "- Growth Hacker Marketing — Ryan Holiday  \n",
      "  Ryan Holiday reframes modern marketing around rapid experimentation, low-cost tactics, and product-market fit, championing “growth hacking” as a mindset that prioritizes scalable acquisition over traditional advertising. The book offers case studies and step-by-step tactics used by startups to grow quickly.\n",
      "\n",
      "- Hacking Growth — Sean Ellis and Morgan Brown  \n",
      "  A playbook from practitioners Sean Ellis and Morgan Brown that lays out the cross-functional growth team model, processes for hypothesis-driven experimentation, and tools to systematically increase user acquisition, activation, retention, and revenue. It blends strategy, metrics, and operational recipes used at fast-growing companies.\n",
      "\n",
      "- Monetizing Innovation — Madhavan Ramanujam and Georg Tacke  \n",
      "  This book provides a framework for pricing and product strategy that starts with customer willingness-to-pay, arguing that monetization should drive product decisions rather than follow them. Ramanujam and Tacke present research-backed methods and examples to design offerings customers will pay for.\n",
      "\n",
      "- Audience-Ology — Kevin Goetz  \n",
      "  Kevin Goetz offers a marketer’s guide to deeply understanding and segmenting audiences, using customer psychology and lifecycle mapping to create more relevant messaging and higher-converting campaigns. The book stresses research-driven audience profiles and tactical targeting approaches.\n",
      "\n",
      "- Everybody Writes — Ann Handley  \n",
      "  Ann Handley’s practical manual for modern business writing emphasizes clarity, empathy, and storytelling to create content that engages customers and supports marketing goals. It combines style rules, tips, and examples to help professionals write better every day.\n",
      "\n",
      "- Hook Point — Brendan Kane  \n",
      "  Brendan Kane teaches how to craft ultra-short, attention-grabbing messages (“hook points”) that cut through today’s noisy media environment and compel audiences to stop scrolling and engage. The book offers techniques and real-world tests for optimizing headlines, openings, and creative formats.\n",
      "\n",
      "- Converted — Neil Hoyne  \n",
      "  Neil Hoyne focuses on the science and practice of turning prospects into customers by optimizing the conversion funnel with data, testing, and measurement frameworks. It emphasizes building predictive models, tracking the right metrics, and aligning teams to systematically improve conversion outcomes.\n"
     ]
    }
   ],
   "source": [
    "book_titles = \"\\n\".join(highlights_to_synthesize['title_author'].unique())\n",
    "book_summary_prompt = (\n",
    "    \"Describe each book and author in 1-2 sentences. Output in a markdown list.\\n\"\n",
    "    f\"{book_titles}\"\n",
    ")\n",
    "\n",
    "book_summary_response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=[{\"role\": \"user\", \"content\": book_summary_prompt}],\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    tool_choice=\"auto\",\n",
    "    reasoning={\"effort\": \"low\"}\n",
    ")\n",
    "\n",
    "print(book_summary_response.output_text)\n",
    "\n",
    "# save book_summary_response.output_text to a markdown file\n",
    "with open(f'book_summary_{timestamp}.md', 'w') as f:\n",
    "    f.write(book_summary_response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0eded",
   "metadata": {},
   "source": [
    "### OpenAI API: Generate Marketing Fundamentals (based on highlights from Ogilvy on Advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogilvy_highlights = highlights_to_synthesize.query('title_author == \"Ogilvy on Advertising by David Ogilvy\"')\n",
    "\n",
    "ogilvy_csv = ogilvy_highlights['highlight_text'].to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ad1c2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ogilvy_prompt = f\"\"\"\n",
    "You are an expert in marketing and advertising fundamentals, trained in the style and philosophy of David Ogilvy.\n",
    "\n",
    "You will receive a list of Kindle highlights in CSV format. Each row contains a quote or note written by David Ogilvy from his books, interviews, or writings.\n",
    "\n",
    "Your task:\n",
    "1. Read all the highlights carefully.\n",
    "2. Group the highlights into 10 key principles that best capture David Ogilvy’s timeless fundamentals of marketing and advertising.\n",
    "3. For each principle, provide:\n",
    "   - A short, memorable title (3–6 words)\n",
    "   - A clear description (1–2 sentences)\n",
    "   - 1–2 representative quotes from the highlights that best illustrate the principle (if the highlight is an incomplete quote then use light web search to find the full quote or fill in the idea)\n",
    "4. Number the principles.\n",
    "\n",
    "Output format (in markdown only):\n",
    "\n",
    "### <Principle>\n",
    "- <Description>\n",
    "- <Supporting Quotes/Ideas>\n",
    "\n",
    "Do not output JSON or tables. Keep your response in readable markdown.\n",
    "Focus on clarity, persuasion, and Ogilvy’s distinct voice and principles.\n",
    "\n",
    "Input:\n",
    "{ogilvy_csv}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e35969f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1) Product First, Always\n",
      "- Superior product performance is the foundation; advertising can only accelerate what people already find genuinely valuable.\n",
      "- “The best way to increase the sale of a product is to improve the product.” • “The key to successful marketing is superior product performance.…If the consumer does not perceive any real benefits in the brand, then no amount of ingenious advertising and selling can save it.”\n",
      "\n",
      "### 2) Homework Before Headlines\n",
      "- Know more than anyone about the product, the market, and the competition; insight precedes imagination.\n",
      "- “First, study the product you are going to advertise. The more you know about it, the more likely you are to come up with a big idea for selling it.” • “What distinguishes the great surgeon is that he knows more than other surgeons. It is the same with advertising agents. The good ones know more.”\n",
      "\n",
      "### 3) Hunt the Big Idea\n",
      "- Only a big, relevant, long-lived idea will win attention and drive action; otherwise your ad slips by unnoticed.\n",
      "- “It takes a big idea to attract the attention of consumers and get them to buy your product.” • “Unless your advertising contains a big idea, it will pass like a ship in the night.”\n",
      "\n",
      "### 4) Build Enduring Brand Image\n",
      "- Every execution must add to a clear, consistent brand personality that people choose as much for its image as for its function.\n",
      "- “Every advertisement should be thought of as a contribution to the brand image.” • “The brand image is 90 per cent of what the distiller has to sell.”\n",
      "\n",
      "### 5) Headlines Do the Heavy Lifting\n",
      "- Headlines carry most of the selling power; promise a benefit, deliver news, or offer a service right up top.\n",
      "- “On the average, five times as many people read the headlines as read the body copy.” • “The headlines which work best are those which promise the reader a benefit.”\n",
      "\n",
      "### 6) Be Simple. Be Clear.\n",
      "- Cut complexity; use plain words, short sentences, and crystal-clear demonstrations so no one can misunderstand you.\n",
      "- “Most campaigns are too complicated… By attempting to cover too many things, they achieve nothing.” • “If you want to avoid your television commercials being misunderstood, you had better make them crystal clear.”\n",
      "\n",
      "### 7) Test, Then Scale\n",
      "- Treat advertising as a laboratory: test promises, prices, formats, and media; keep and repeat what works, discard what doesn’t.\n",
      "- “Experienced practitioners always test some variables…” • “If you are lucky enough to write a good advertisement, repeat it until it stops selling.”\n",
      "\n",
      "### 8) Sell, Don’t Entertain\n",
      "- Creativity is only creative if it sells; apply direct-response rigor to all advertising.\n",
      "- “What is a good advertisement? …an advertisement which sells the most.” • “The Benton & Bowles agency holds that ‘if it doesn’t sell, it isn’t creative.’”\n",
      "\n",
      "### 9) Differentiate with Meaning\n",
      "- There is no commodity; position on a distinctive, persuasive promise—quality, value, or service—and make it unmistakable.\n",
      "- “Professor Levitt, ‘there is no such thing as a commodity. All goods and services are differentiable.’” • “Try to find a promise which is not only persuasive, but also unique.”\n",
      "\n",
      "### 10) Respect the Consumer\n",
      "- Speak truth, give facts, show price, and treat people with intelligence and respect; credibility compounds.\n",
      "- “The consumer is not a moron, she is your wife.” • “The more facts you tell, the more you sell.”\n"
     ]
    }
   ],
   "source": [
    "ogilvy_response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=[{\"role\": \"user\", \"content\": ogilvy_prompt}],\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    tool_choice=\"auto\",\n",
    "    reasoning={\"effort\": \"medium\"}\n",
    ")\n",
    "\n",
    "print(ogilvy_response.output_text)\n",
    "\n",
    "# save ogilvy_response.output_text to a markdown file\n",
    "with open(f'ogilvy_response_{timestamp}.md', 'w') as f:\n",
    "    f.write(ogilvy_response.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cursor LangChain 3.11",
   "language": "python",
   "name": "cursor-langchain-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
